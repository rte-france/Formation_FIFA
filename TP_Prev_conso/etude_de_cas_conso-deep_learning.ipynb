{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP Prévision de consommation avec réseau de neurones\n",
    "\n",
    "\n",
    "<img src=\"pictures/Présentation_FormationIA_TPDeepLearning.png\" width=1000 >\n",
    "\n",
    "**Dans l'épisode précédent**  \n",
    "\n",
    "La partie \"visualisation de données\" nous a donné des premiers résultats et des premières intuitions sur notre problème de prévision de consommation pour le lendemain. \n",
    "\n",
    "Nous avons pu analyser des profils de courbe de consommation au jour, à la semaine, au mois. Nous avons également observé la dépendance entre la consommation et la consommation retardée. Nous avons aussi vu l'impact des jours fériés. \n",
    "\n",
    "Nous avons ensuite utilisé de premiers modèles de régressoins pour apprendre par observations l'influence de différents contextes sur la consommation sans les décrires explicitement selon des lois. Nous sommes arrivés à une erreur moyenne de test de 2,8%, bien mieux que ce qui avait été obtenu via une approche naïve.\n",
    "\n",
    "Des difficultés se sont posées pour intégrer les variables météorologiques très dépendantes entre elles et pour intégrer un vecteur de consommation retardée.\n",
    "\n",
    "Avec l'approche classique exposée dans ce TP1, nous avons en particulier constaté le besoin d'une expertise et d'un travail autour des variables explicatives pour obtenir un modèle performant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aujourd'hui** \n",
    "\n",
    "Nous allons de nouveau nous attaquer à ce sujet de la prévision de consommation nationale pour le lendemain, mais cette fois en utilisant un modèle de prévision par réseau de neurones. Nous allons exploiter leur capacité à capter ces phénomènes non-linéaires et interdépendants. Nous allons mettre en évidence le moindre besoin en feature engineering en travaillant directement à la granularité de la donnée, sans créer de variables agrégées ou transformées par de l'expertise.\n",
    "\n",
    "**Ce que vous allez voir dans ce second TP**\n",
    "\n",
    "- Un rappel de notre problème et récapitulatif des performances de nos modèles précédents\n",
    "- Une nouvelle méthode numérique pour préparer ses données et faciliter l'apprentissage : la normalisation\n",
    "- La création d'un premier réseau de neurones pour prédire la consommation dans 24h\n",
    "- L'utilisation de tensorboard pour observer en temps réel la courbe d'apprentissage du réseau de neurones\n",
    "- La création de modèles de plus en plus performants en intégrant davantage d'informations dans notre modélisation\n",
    "- L'évaluation des modèles sur 2 types de jeux de test\n",
    "\n",
    "**Ce que vous allez devoir faire**\n",
    "\n",
    "- Compléter les quelques trous de codes que nous vous avons laissé si vous le souhaitez. La solution est disponible dans le TP complété.\n",
    "- Répondre aux quelques questions disséminées dans ce TP\n",
    "- Entrainer votre propre modèle pour améliorer les performances d'un modèle existant et essayer de remporter notre mini-challenge !\n",
    "\n",
    "__NB__ : Pour ce TP nous utiliserons Keras, une bibliothèque python de haut niveau qui appelle des fonctions de la librairie TensorFlow. D'autres librairies existent, Keras a été retenue en raison de sa facilité d'utilisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionnement en temps\n",
    "La durée estimée de ce TP est d'environ 1h30 :\n",
    "- 10 minutes pour charger les données pour les réseaux de neurones \n",
    "- 20 minutes pour entrainer un premier modèle de réseau de neurones, en examiner le code implémentant ce réseau de neurones\n",
    "- Le reste pour jouer et tenter d'améliorer la qualité de la prédiction avec de nouvelles variables explicatives, ou en choisissant d'autres hyper-paramètres. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I) Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des librairies nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "isInColab = False #False if in Jupyter\n",
    "isDataFromGithub = False #True especially if using colab as it only download the notebook and not the entire github repository. Otherwise with Binder or in local, set it False\n",
    "if isInColab:\n",
    "    isDataFromGithub = True\n",
    "else:\n",
    "    isDataFromGithub = False\n",
    "\n",
    "if(isDataFromGithub):\n",
    "    data_folder = 'https://raw.githubusercontent.com/rte-france/Formation_FIFA/master/tp_prev_conso/data'#data depuis github\n",
    "    root_folder = 'https://raw.githubusercontent.com/rte-france/Formation_FIFA/master/tp_prev_conso'\n",
    "else:\n",
    "    data_folder = os.path.join(os.getcwd(), \"data\") #data en local\n",
    "    root_folder = os.path.dirname(data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.30.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import zipfile\n",
    "import requests, io \n",
    "from urllib.request import urlopen\n",
    "import joblib\n",
    "import tempfile\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot, iplot_mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn est la librairie de machine learning en python et scipy une librairie statistiques\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Keras est la librairie que nous utilisons pour se créer des modèles de réseau de neurones\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Embedding, LSTM, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from tensorflow.keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.utils as tf_utils\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import pydot\n",
    "import graphviz\n",
    "from IPython.display import display_png\n",
    "\n",
    "# set seed for rng\n",
    "tf_utils.set_random_seed(\n",
    "    42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if(isInColab):                      # to have iplot working in colab\n",
    "    import plotly.io as pio\n",
    "    #pio.renderers\n",
    "    pio.renderers.default = 'colab'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I) Récupération et préparation des données\n",
    "\n",
    "Dans cette partie nous allons charger les fichiers csv nécessaires pour l'analyse, puis les convertir en data-frame python. Les données de base à récupérer sont :\n",
    "- la base de données issues du TP1 (Les historiques de consommation, leur lag, les données météo en température, leur lag, les jours feriés) \n",
    "\n",
    "En terme de transformation des données pour mieux les préparer:\n",
    "\n",
    "- nous allons aussi voir comment normaliser les données, une transformation souvent bien utile en pratique pour une meilleure convergence numérique. \n",
    "\n",
    "Cela vient compléter les transformations vu précédemment pour les données calendaires, et aussi la transformation \"one-hot\" pour les données catégorielles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupération de nos variables à prédire: la consommation française"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>conso_real</th>\n",
       "      <th>conso_real_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-02 00:00:00+00:00</td>\n",
       "      <td>59416</td>\n",
       "      <td>0.453969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-02 01:00:00+00:00</td>\n",
       "      <td>54881</td>\n",
       "      <td>0.070665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-02 02:00:00+00:00</td>\n",
       "      <td>54007</td>\n",
       "      <td>-0.003206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-02 03:00:00+00:00</td>\n",
       "      <td>51534</td>\n",
       "      <td>-0.212227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-02 04:00:00+00:00</td>\n",
       "      <td>49379</td>\n",
       "      <td>-0.394370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ds  conso_real  conso_real_scaled\n",
       "0 2014-01-02 00:00:00+00:00       59416           0.453969\n",
       "1 2014-01-02 01:00:00+00:00       54881           0.070665\n",
       "2 2014-01-02 02:00:00+00:00       54007          -0.003206\n",
       "3 2014-01-02 03:00:00+00:00       51534          -0.212227\n",
       "4 2014-01-02 04:00:00+00:00       49379          -0.394370"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43551, 3)\n"
     ]
    }
   ],
   "source": [
    "y_csv = os.path.join(data_folder, \"y_conso_tp2.csv\")\n",
    "y = pd.read_csv(y_csv, sep=\";\", engine='c', header=0)\n",
    "\n",
    "y['ds'] = pd.to_datetime(y['ds'], utc=True)\n",
    "\n",
    "display(y.head(5))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "* Petit rappel, que fait la fonction \"shape\" ?\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données météo sont confidentielles, et donc ont été cryptées. Pour les lire vous avez besoin d'un mot de passe qui ne peut vous être donné que dans le cadre d'un travail au sein de RTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "password = \"FIFA_Meteo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>is_bank_holiday</th>\n",
       "      <th>temperature_real_24h_avant</th>\n",
       "      <th>temperature_real_24h_avant_scaled</th>\n",
       "      <th>temperature_prevue</th>\n",
       "      <th>temperature_prevue_scaled</th>\n",
       "      <th>conso_real_24h_avant</th>\n",
       "      <th>conso_real_24h_avant_scaled</th>\n",
       "      <th>month_1</th>\n",
       "      <th>month_2</th>\n",
       "      <th>...</th>\n",
       "      <th>hour_15</th>\n",
       "      <th>hour_16</th>\n",
       "      <th>hour_17</th>\n",
       "      <th>hour_18</th>\n",
       "      <th>hour_19</th>\n",
       "      <th>hour_20</th>\n",
       "      <th>hour_21</th>\n",
       "      <th>hour_22</th>\n",
       "      <th>hour_23</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-02 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>6.46539</td>\n",
       "      <td>-0.968581</td>\n",
       "      <td>8.850575</td>\n",
       "      <td>-0.615538</td>\n",
       "      <td>64660.0</td>\n",
       "      <td>0.897874</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-02 01:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>6.33415</td>\n",
       "      <td>-0.988059</td>\n",
       "      <td>8.805705</td>\n",
       "      <td>-0.622207</td>\n",
       "      <td>61362.0</td>\n",
       "      <td>0.619043</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-02 02:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>6.26140</td>\n",
       "      <td>-0.998856</td>\n",
       "      <td>8.749935</td>\n",
       "      <td>-0.630496</td>\n",
       "      <td>60748.0</td>\n",
       "      <td>0.567132</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-02 03:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>6.30562</td>\n",
       "      <td>-0.992293</td>\n",
       "      <td>8.690715</td>\n",
       "      <td>-0.639297</td>\n",
       "      <td>58061.0</td>\n",
       "      <td>0.339958</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-02 04:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>6.12588</td>\n",
       "      <td>-1.018970</td>\n",
       "      <td>8.641280</td>\n",
       "      <td>-0.646644</td>\n",
       "      <td>54475.0</td>\n",
       "      <td>0.036778</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ds  is_bank_holiday  temperature_real_24h_avant  \\\n",
       "0 2014-01-02 00:00:00+00:00                0                     6.46539   \n",
       "1 2014-01-02 01:00:00+00:00                0                     6.33415   \n",
       "2 2014-01-02 02:00:00+00:00                0                     6.26140   \n",
       "3 2014-01-02 03:00:00+00:00                0                     6.30562   \n",
       "4 2014-01-02 04:00:00+00:00                0                     6.12588   \n",
       "\n",
       "   temperature_real_24h_avant_scaled  temperature_prevue  \\\n",
       "0                          -0.968581            8.850575   \n",
       "1                          -0.988059            8.805705   \n",
       "2                          -0.998856            8.749935   \n",
       "3                          -0.992293            8.690715   \n",
       "4                          -1.018970            8.641280   \n",
       "\n",
       "   temperature_prevue_scaled  conso_real_24h_avant  \\\n",
       "0                  -0.615538               64660.0   \n",
       "1                  -0.622207               61362.0   \n",
       "2                  -0.630496               60748.0   \n",
       "3                  -0.639297               58061.0   \n",
       "4                  -0.646644               54475.0   \n",
       "\n",
       "   conso_real_24h_avant_scaled  month_1  month_2  ...  hour_15  hour_16  \\\n",
       "0                     0.897874        1        0  ...        0        0   \n",
       "1                     0.619043        1        0  ...        0        0   \n",
       "2                     0.567132        1        0  ...        0        0   \n",
       "3                     0.339958        1        0  ...        0        0   \n",
       "4                     0.036778        1        0  ...        0        0   \n",
       "\n",
       "   hour_17  hour_18  hour_19  hour_20  hour_21  hour_22  hour_23  weekday  \n",
       "0        0        0        0        0        0        0        0        1  \n",
       "1        0        0        0        0        0        0        0        1  \n",
       "2        0        0        0        0        0        0        0        1  \n",
       "3        0        0        0        0        0        0        0        1  \n",
       "4        0        0        0        0        0        0        0        1  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43551, 45)\n"
     ]
    }
   ],
   "source": [
    "# Récupération des températures et jours fériés\n",
    "x_zip = os.path.join(data_folder, \"x_input_tp2.zip\")\n",
    "\n",
    "if(isDataFromGithub):\n",
    "    ####data sur github\n",
    "    r = requests.get(x_zip)\n",
    "    x_zip_object = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "else:\n",
    "    ######data en local\n",
    "    x_zip_object = zipfile.ZipFile(x_zip)\n",
    "    \n",
    "x_zip_object.setpassword(bytes(password,'utf-8'))\n",
    "x = pd.read_csv(x_zip_object.open('x.csv'), sep=\";\", engine='c', header=0)\n",
    "\n",
    "x['ds'] = pd.to_datetime(x['ds'], utc=True)\n",
    "\n",
    "display(x.head(5))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dejaegherjer\\AppData\\Local\\miniconda3\\envs\\colab20240404\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning:\n",
      "\n",
      "Trying to unpickle estimator StandardScaler from version 0.24.1 when using version 1.4.1.post1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# On récupère aussi le scaler qui permet de dénormaliser la prédiction du réseau de neurones\n",
    "if(isDataFromGithub):\n",
    "    scaler_conso_nat = joblib.load(urlopen(os.path.join(data_folder, \"scaler_conso.save\")))\n",
    "else:\n",
    "    scaler_conso_nat = joblib.load(os.path.join(data_folder, \"scaler_conso.save\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "\n",
    "**A propos de la normalisation...**\n",
    "\n",
    "\n",
    "</font>\n",
    "\n",
    "En théorie, la normalisation des données d'entrée n'est pas indispensable pour entrainer un réseau de neurones.  \n",
    "\n",
    "En effet, on devrait apprendre des poids et biais plus ou moins importants pour équilibrer les contributions des différentes variables explicatives en entrée. \n",
    "\n",
    "Cependant en pratique, normaliser les données d'entrée permet généralement d'obtenir un apprentissage plus rapide du réseau de neurones.\n",
    "\n",
    "<br/>\n",
    "<font color='green'>\n",
    "    \n",
    "* Comment l'expliquez-vous ?\n",
    "\n",
    "<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II) Création des jeux d'apprentissage, de validation, et de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "    \n",
    "**Question** : \n",
    "* A quoi servent les jeux d'entrainement, de validation, et de test ?\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons nous créer les jeux de données suivants :\n",
    "* Jeu d'entrainement : 90% des points pris aléatoirement entre le début du dataset et le 31 décembre 2017\n",
    "* Jeu de validation : les 10% restant des points entre le début du dataset et le 31 décembre 2017\n",
    "* Jeu de test : tous les points horaires à partir du 1er janvier 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43551, 45)\n",
      "Nombre d'éléments dans le train set : 31558\n",
      "Nombre d'éléments dans le validation set : 3481\n",
      "Nombre d'éléments dans le test set : 8512\n",
      "43551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dejaegherjer\\AppData\\Local\\Temp\\ipykernel_25228\\475313239.py:13: FutureWarning:\n",
      "\n",
      "Logical ops (and, or, xor) between Pandas objects and dtype-less sequences (e.g. list, tuple) are deprecated and will raise in a future version. Wrap the object in a Series, Index, or np.array before operating instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# D'abord on repère les lignes de chacun des set\n",
    "\n",
    "TEST_START_DATE = datetime.datetime(year=2018, month=1, day=1, tzinfo=datetime.timezone.utc)\n",
    "\n",
    "mask_test_set = (x[\"ds\"] >= TEST_START_DATE)\n",
    "\n",
    "mask_train_validation = (x['ds'] < TEST_START_DATE)\n",
    "mask_train_validation = mask_train_validation.astype(bool)\n",
    "\n",
    "def filter(value, threshold):\n",
    "    return True if value < threshold else False\n",
    "    \n",
    "mask_train_set = [filter(value, 0.9) for value in np.random.uniform(0, 1, size=x.shape[0])] & mask_train_validation\n",
    "mask_validation_set = ~mask_train_set & mask_train_validation\n",
    "\n",
    "# petite verif\n",
    "print(x.shape)\n",
    "print(\"Nombre d'éléments dans le train set : \" + str(np.sum(mask_train_set)))\n",
    "print(\"Nombre d'éléments dans le validation set : \" + str(np.sum(mask_validation_set)))\n",
    "print(\"Nombre d'éléments dans le test set : \" + str(np.sum(mask_test_set)))\n",
    "print(np.sum(mask_train_set) + np.sum(mask_validation_set) + np.sum(mask_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ds', 'is_bank_holiday', 'temperature_real_24h_avant',\n",
      "       'temperature_real_24h_avant_scaled', 'temperature_prevue',\n",
      "       'temperature_prevue_scaled', 'conso_real_24h_avant',\n",
      "       'conso_real_24h_avant_scaled', 'month_1', 'month_2', 'month_3',\n",
      "       'month_4', 'month_5', 'month_6', 'month_7', 'month_8', 'month_9',\n",
      "       'month_10', 'month_11', 'month_12', 'hour_0', 'hour_1', 'hour_2',\n",
      "       'hour_3', 'hour_4', 'hour_5', 'hour_6', 'hour_7', 'hour_8', 'hour_9',\n",
      "       'hour_10', 'hour_11', 'hour_12', 'hour_13', 'hour_14', 'hour_15',\n",
      "       'hour_16', 'hour_17', 'hour_18', 'hour_19', 'hour_20', 'hour_21',\n",
      "       'hour_22', 'hour_23', 'weekday'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>is_bank_holiday</th>\n",
       "      <th>temperature_real_24h_avant</th>\n",
       "      <th>temperature_real_24h_avant_scaled</th>\n",
       "      <th>temperature_prevue</th>\n",
       "      <th>temperature_prevue_scaled</th>\n",
       "      <th>conso_real_24h_avant</th>\n",
       "      <th>conso_real_24h_avant_scaled</th>\n",
       "      <th>month_1</th>\n",
       "      <th>month_2</th>\n",
       "      <th>...</th>\n",
       "      <th>hour_15</th>\n",
       "      <th>hour_16</th>\n",
       "      <th>hour_17</th>\n",
       "      <th>hour_18</th>\n",
       "      <th>hour_19</th>\n",
       "      <th>hour_20</th>\n",
       "      <th>hour_21</th>\n",
       "      <th>hour_22</th>\n",
       "      <th>hour_23</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-02 00:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>6.46539</td>\n",
       "      <td>-0.968581</td>\n",
       "      <td>8.850575</td>\n",
       "      <td>-0.615538</td>\n",
       "      <td>64660.0</td>\n",
       "      <td>0.897874</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-02 01:00:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>6.33415</td>\n",
       "      <td>-0.988059</td>\n",
       "      <td>8.805705</td>\n",
       "      <td>-0.622207</td>\n",
       "      <td>61362.0</td>\n",
       "      <td>0.619043</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ds  is_bank_holiday  temperature_real_24h_avant  \\\n",
       "0 2014-01-02 00:00:00+00:00                0                     6.46539   \n",
       "1 2014-01-02 01:00:00+00:00                0                     6.33415   \n",
       "\n",
       "   temperature_real_24h_avant_scaled  temperature_prevue  \\\n",
       "0                          -0.968581            8.850575   \n",
       "1                          -0.988059            8.805705   \n",
       "\n",
       "   temperature_prevue_scaled  conso_real_24h_avant  \\\n",
       "0                  -0.615538               64660.0   \n",
       "1                  -0.622207               61362.0   \n",
       "\n",
       "   conso_real_24h_avant_scaled  month_1  month_2  ...  hour_15  hour_16  \\\n",
       "0                     0.897874        1        0  ...        0        0   \n",
       "1                     0.619043        1        0  ...        0        0   \n",
       "\n",
       "   hour_17  hour_18  hour_19  hour_20  hour_21  hour_22  hour_23  weekday  \n",
       "0        0        0        0        0        0        0        0        1  \n",
       "1        0        0        0        0        0        0        0        1  \n",
       "\n",
       "[2 rows x 45 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x.columns)\n",
    "x.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puis on constitue les sets\n",
    "x_train_full = x[mask_train_set]\n",
    "x_validation_full = x[mask_validation_set]\n",
    "x_test_full = x[mask_test_set]\n",
    "\n",
    "y_train_full = y[mask_train_set]\n",
    "y_validation_full = y[mask_validation_set]\n",
    "y_test_full = y[mask_test_set]\n",
    "\n",
    "x_train_full.reset_index(inplace=True, drop=True)\n",
    "x_validation_full.reset_index(inplace=True, drop=True)\n",
    "x_test_full.reset_index(inplace=True, drop=True)\n",
    "y_train_full.reset_index(inplace=True, drop=True)\n",
    "y_validation_full.reset_index(inplace=True, drop=True)\n",
    "y_test_full.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de x_train_full : (31558, 45)\n",
      "Shape de x_validation_full : (3481, 45)\n",
      "Shape de x_test_full : (8512, 45)\n",
      "Shape de y_train : (31558, 3)\n",
      "Shape de y_validation : (3481, 3)\n",
      "Shape de y_test : (8512, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape de x_train_full : \" + str(x_train_full.shape))\n",
    "print(\"Shape de x_validation_full : \" + str(x_validation_full.shape))\n",
    "print(\"Shape de x_test_full : \" + str(x_test_full.shape))\n",
    "\n",
    "print(\"Shape de y_train : \" + str(y_train_full.shape))\n",
    "print(\"Shape de y_validation : \" + str(y_validation_full.shape))\n",
    "print(\"Shape de y_test : \" + str(y_test_full.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_light_columns = [\"conso_real_scaled\"]\n",
    "\n",
    "y_train_light = y_train_full[y_light_columns]\n",
    "y_validation_light = y_validation_full[y_light_columns]\n",
    "y_test_light = y_test_full[y_light_columns]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III) Getting started with Keras API\n",
    "\n",
    "Jusqu'ici, nous avons importé nos données. Nous les avons ensuite préparées pour les fournir au réseau de neurones (one-hot encoding, normalisation). Nous avons également créé nos jeux d'entrainement, validation, et de test.\n",
    "\n",
    "Il est maintenant l'heure de se construire un réseau de neurones, de l'entrainer, et de lui faire faire des prédictions !\n",
    "\n",
    "Dans cette partie III) nous allons nous familiariser avec la librairie Keras qui permet d'implémenter des réseaux de neurones, puis en partie IV) nous l'appliquerons à notre problématique de prévision de consommation.\n",
    "\n",
    "**Cette partie III) est générique et indépendante de notre problématique de prévision de consommation**\n",
    "\n",
    "<img src=\"pictures/FirstNeuralNetwork.jpeg\" width=700 >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deux fonctions bien utiles\n",
    "\n",
    "Nous allons commencer par implémenter deux fonctions que nous appellerons pour chacun des modèles que nous allons tester:\n",
    "- Fonction 1: **new_keras_model**, pour instancier un modèle de réseau de neurone avant apprentissage\n",
    "- Fonction 2: **plot_neural_net**, pour visualiser un réseau de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création d'une architecture de réseau de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_keras_model(n_inputs, n_outputs=1, hidden_layers=None, activation='relu'):\n",
    "    \"\"\"      \n",
    "    arguments\n",
    "        - n_inputs : le nombre de features en entrée\n",
    "        - n_outputs : le nombre de sorties (variables à prédire)\n",
    "        - hidden_layers : une liste. \n",
    "                          La taille de la liste donne le nombre de couches cachées.\n",
    "                          Les éléments de la liste donnent le nombre de neurones par couche.\n",
    "                          Cette liste doit contenir au moins un élément\n",
    "        - activation: `str` \"relu\" ou \"sigmoid\" le type de \"non linéarité\" / \"fonction d'activation\"\n",
    "                      que vous voulez utiliser.\n",
    "        \n",
    "    returns\n",
    "        - un objet de type Model \n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    input_dim = n_inputs\n",
    "    print(n_inputs)\n",
    "    for l_size in hidden_layers:\n",
    "        model.add(Dense(l_size, input_dim=input_dim, activation=activation))\n",
    "        input_dim = l_size\n",
    "\n",
    "    # Pour une régression, la fonction d'activation finale est simplement la fonction identité\n",
    "    model.add(Dense(n_outputs, input_dim=input_dim, activation='linear'))  \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspection de l'architecture d'un reseau de neurones\n",
    "On se créé un réseau avec un certains nombre de couches qui peuvent chacune avoir différentes dimensions. On peut ensuite inspecter les dimensions et le nombre de paramètres de ce réseau avec la méthode _summary_ de Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dejaegherjer\\AppData\\Local\\miniconda3\\envs\\colab20240404\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">88</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │            \u001b[38;5;34m90\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m88\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │            \u001b[38;5;34m54\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m7\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">239</span> (956.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m239\u001b[0m (956.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">239</span> (956.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m239\u001b[0m (956.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# on se crée un réseau de neurones avec un certains nombre d'entrées et sorties\n",
    "n_inputs = 8  #un choix raisonnable pour visualiser ce modèle ensuite\n",
    "n_outputs = 1\n",
    "\n",
    "hidden_layers = [10, n_inputs, 6]\n",
    "dummy_model = new_keras_model(n_inputs, n_outputs, hidden_layers=hidden_layers)\n",
    "dummy_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créons-nous maintenant une fonction pour dessiner ce réseau de neurones.\n",
    "\n",
    "Ne vous embêtez pas trop à comprendre le code de la fonction *plot_neural_net*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_neural_net(model):\n",
    "    layers = [model.input_shape[1]]\n",
    "    for layer in model.layers:\n",
    "        layers.append(layer.get_output_at(0).get_shape().as_list()[1])\n",
    "        \n",
    "    tmp_file = os.path.join(tempfile.gettempdir(), 'out.dot')                \n",
    "    with open(tmp_file, 'w') as f:       \n",
    "        layers_str = [\"Input\"] + [\"Hidden\"] * (len(layers) - 2) + [\"Output\"]\n",
    "        layers_col = [\"none\"] + [\"none\"] * (len(layers) - 2) + [\"none\"]\n",
    "        layers_fill = [\"black\"] + [\"gray\"] * (len(layers) - 2) + [\"black\"]\n",
    "        penwidth = 15\n",
    "        font = \"Hilda 10\"\n",
    "        print(\"digraph G {\",file=f)\n",
    "        print(\"\\tfontname = \\\"{}\\\"\".format(font),file=f)\n",
    "        print(\"\\trankdir=LR\",file=f)\n",
    "        print(\"\\tsplines=line\",file=f)\n",
    "        print(\"\\tnodesep=.08;\",file=f)\n",
    "        print(\"\\tranksep=1;\",file=f)\n",
    "        print(\"\\tedge [color=black, arrowsize=.5];\",file=f)\n",
    "        print(\"\\tnode [fixedsize=true,label=\\\"\\\",style=filled,\" + \\\n",
    "              \"color=none,fillcolor=gray,shape=circle]\\n\",file=f)\n",
    "\n",
    "        # Clusters\n",
    "        for i in range(0, len(layers)):\n",
    "            print((\"\\tsubgraph cluster_{} {{\".format(i)),file=f)\n",
    "            print((\"\\t\\tcolor={};\".format(layers_col[i])),file=f)\n",
    "            print((\"\\t\\tnode [style=filled, color=white, penwidth={},\"\n",
    "                   \"fillcolor={} shape=circle];\".format(\n",
    "                penwidth,\n",
    "                layers_fill[i])),file=f)\n",
    "            print((\"\\t\\t\"), end=' ',file=f)\n",
    "            for a in range(layers[i]):\n",
    "                print(\"l{}{} \".format(i + 1, a), end=' ',file=f)\n",
    "\n",
    "            print(\";\",file=f)\n",
    "            print((\"\\t\\tlabel = {};\".format(layers_str[i])),file=f)\n",
    "            print(\"\\t}\\n\",file=f)\n",
    "\n",
    "        # Nodes\n",
    "        for i in range(1, len(layers)):\n",
    "            for a in range(layers[i - 1]):\n",
    "                for b in range(layers[i]):\n",
    "                    print(\"\\tl{}{} -> l{}{}\".format(i, a, i + 1, b), file=f)\n",
    "        print(\"}\", file=f)\n",
    "    \n",
    "    dot = graphviz.Source.from_file(tmp_file, engine='dot', format=\"png\")\n",
    "    return dot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisons le reseau de neurone test créé précédemment :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dense' object has no attribute 'get_output_at'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_neural_net(dummy_model)\n",
      "Cell \u001b[1;32mIn[21], line 4\u001b[0m, in \u001b[0;36mplot_neural_net\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      2\u001b[0m layers \u001b[39m=\u001b[39m [model\u001b[39m.\u001b[39minput_shape[\u001b[39m1\u001b[39m]]\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m----> 4\u001b[0m     layers\u001b[39m.\u001b[39mappend(layer\u001b[39m.\u001b[39;49mget_output_at(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mget_shape()\u001b[39m.\u001b[39mas_list()[\u001b[39m1\u001b[39m])\n\u001b[0;32m      6\u001b[0m tmp_file \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(tempfile\u001b[39m.\u001b[39mgettempdir(), \u001b[39m'\u001b[39m\u001b[39mout.dot\u001b[39m\u001b[39m'\u001b[39m)                \n\u001b[0;32m      7\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(tmp_file, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:       \n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Dense' object has no attribute 'get_output_at'"
     ]
    }
   ],
   "source": [
    "plot_neural_net(dummy_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATTENTION: Pour des grandes tailles de reseau, cette visualisation n'est pas adaptée et le temps d'éxécution de cette fonction sera très long !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "    \n",
    "**Défi !** : \n",
    "* Créez vous un reseau de neurones en forme de noeud papillon, dont la couche de sortie fait la même dimension que la couche d'entrée.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# votre new_keras_model à créer ici\n",
    "model_noeud_papillon = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#plot_neural_net(model_noeud_papillon)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bravo ! Vous venez de créer un réseau de neurone d'une classe très particulière: c'est un autoencoder !\n",
    "Pour les curieux, vous pouvez retrouver le bestiaire des réseaux de neurones ici: https://towardsdatascience.com/the-mostly-complete-chart-of-neural-networks-explained-3fb6f2367464"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV) Un premier modèle de réseau de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choix des variables explicatives\n",
    "\n",
    "pour ce TP, nous avons un jeu d'entrée X contenant beaucoup de variables. Afin de commencer par un modèle simple, nous allons élaguer ce X pour réduire le nombre de features en entrée. Dans ce TP, nous allons donc lister les colonnes à retirer des datasets X initialisés ci-dessus.\n",
    "\n",
    "Pour un cas d'étude réel, une approche pragmatique serait de commencer par se créer un premier X simple, de voir les performances du modèle, puis ensuite d'incorporer de plus en plus de features dans le X pour évaluer la progression des performances de nos modèles.\n",
    "\n",
    "Toutefois, en deep learning, il est courant commencer directement en mettant en entrée toute l'information disponible. En effet une des forces des réseaux de neurones est leur capacité à \"digérer\" la donnée, en se nourrissant d'informations redondantes.\n",
    "\n",
    "pour des raisons pédagogiques, nous allons commencer avec la première approche.\n",
    "\n",
    "Pour le premier réseau de neurones que nous allons entrainer, nous allons simplement garder les variables calendaires ainsi que la valeur de consommation nationale réalisée la veille."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Petit rappel pour se remettre en mémoire les variables que nous avons à disposition\n",
    "x_train_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Sélectionnons un sous-ensemble de ces variables\n",
    "x_light_columns = [elt for elt in x.columns if elt not in \n",
    "                   [\"ds\", \"is_bank_holiday\", \"temperature_real_24h_avant\", \"temperature_prevue\", \"conso_real_24h_avant\"]\n",
    "                  ]\n",
    "\n",
    "x_train_light = x_train_full[x_light_columns]\n",
    "x_validation_light = x_validation_full[x_light_columns]\n",
    "x_test_light = x_test_full[x_light_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(\"Shape de x_train_light : \" + str(x_train_light.shape))\n",
    "print(\"Shape de x_validation_light : \" + str(x_validation_light.shape))\n",
    "print(\"Shape de x_test_light : \" + str(x_test_light.shape))\n",
    "\n",
    "print(\"Shape de y_train_light : \" + str(y_train_light.shape))\n",
    "print(\"Shape de y_validation_light : \" + str(y_validation_light.shape))\n",
    "print(\"Shape de y_test_light : \" + str(y_test_light.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du réseau de neurones et hyper-paramétrage\n",
    "Un réseau de neurones profond est constuitué d'un certains nombre de couches, chacune portant un certain nombre de neurones. Ce sont 2 hyperparamètres que vous pouvez faire varier et qui vous permettront d'obtenir un apprentissage plus ou moins précis, en utilisant plus ou moins de puissance de calcul.\n",
    "\n",
    "Le \"learning rate\" de l'optimiseur est également un hyperparamètre qui influencera la convergence et la vitesse de convergence de l'apprentissage, où l'on cherche à optimiser notre modèle pour minimiser l'erreur de prédiction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "n_inputs = x_train_light.shape[1]  # nombre de features en entrée du réseau de neurones\n",
    "n_outputs = y_train_light.shape[1]\n",
    "hidden_layers = [n_inputs, n_inputs, n_inputs, n_inputs, n_inputs]\n",
    "\n",
    "first_model = new_keras_model(n_inputs, n_outputs, hidden_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# on affiche le nombre de paramètres de ce modèle avec la fonction summary de Keras\n",
    "first_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "first_model.compile(\n",
    "    loss='mean_squared_error', \n",
    "    optimizer=Adam(lr=0.001), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# On crée ici une instance de l'utilitaire tensorboard qui va nous permettre de visualiser \n",
    "# les courbes d'apprentissage de nos différents modèles.\n",
    "# On reviendra avec plus d'explication sur TensorBoard un peu plus tard.\n",
    "# Donner un nom a votre modele pour le retrouver dans les logs tensorboard\n",
    "model_name = \"my_first_model_\" + datetime.datetime.now().strftime(\"%H-%M-%S\")\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(model_name))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement\n",
    "\n",
    "La cellule suivante peut prendre un peu de temps à s'exécuter. On reconnait là la méthode **fit** commune à chaque modèle de machine-learning pour entraîner son modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Paramètres d'appel\n",
    "# - epoch: on précise le nombre d'epochs (le nombre de fois que l'on voit le jeu d'apprentissage en entier)\n",
    "# - batch size: le nombre d'exemples sur lequel on fait un \"pas\" d'apprentissage parmi tout le jeu\n",
    "# - validation_split: la proportion d'exemples que l'on conserve pour notre jeu de validation\n",
    "# - callbacks: pour appeler des utilitaires/fonctions externes pour récupérer des résultats\n",
    "first_model.fit(\n",
    "    x_train_light, \n",
    "    y_train_light, \n",
    "    epochs=100, \n",
    "    batch_size=100, \n",
    "    validation_data=(x_validation_light, y_validation_light),\n",
    "    callbacks=[tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "* D'après les informations de logs exposées ici, quelle semble être la perfomance atteinte par votre réseau de neurones ? \n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard\n",
    "c'est un utilitaire de tensorflow qui permet de visualiser en temps réel les courbes d'apprentissage des réseau de neurones et est donc utile pour arrêter l'apprentissage si les progrès sont faibles.\n",
    "\n",
    "En particulier, vous pouvez vous intéresser à la courbe de l'erreur (loss) d'entrainement et de validation pour visualiser la progression de l'apprentissage et une tendance au surapprentissage en fin d'apprentissage.\n",
    "\n",
    "<img src=\"pictures/CourbesTensorboard.png\" width=1000 >\n",
    "\n",
    "**Pour ouvrir une fenêtre tensorboard, revenez sur la page d'accueil de Jupyter, placez vous dans le dossier logs dans lequel se trouve les logs de vos entrainement, puis cliquez sur New (en haut à droite) et enfin sur Tensorboard**.\n",
    "\n",
    "Une fenêtre pop-up doit s'ouvrir. Si elle est bloquée, autorisez son ouverture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#or you can directly load tensorboard in the notebook - especially if you are on Colab and not in Jupyter\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "* Vous devriez visualiser les courbes de 2 modèles: celui que vous venez d'entrainer et un modèle qui avait été entrainé de la même manière mais avec des données non normalisée. Que constatez-vous ? Comment l'expliquez-vous ?\n",
    "<br/><br/>\n",
    "* Il se passe quelque chose d'étonnant vers l'epoch 50. Qu'est-ce que cela vous inspire ?\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation de la qualité du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "predictions_train_scaled = first_model.predict(x_train_light)\n",
    "predictions_val_scaled = first_model.predict(x_validation_light)\n",
    "predictions_test_scaled = first_model.predict(x_test_light)\n",
    "\n",
    "predictions_train = scaler_conso_nat.inverse_transform(predictions_train_scaled).reshape(-1)\n",
    "predictions_val = scaler_conso_nat.inverse_transform(predictions_val_scaled).reshape(-1)\n",
    "predictions_test = scaler_conso_nat.inverse_transform(predictions_test_scaled).reshape(-1)\n",
    "\n",
    "print(predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "relative_error_on_train = np.abs((y_train_full['conso_real'] - predictions_train) / y_train_full['conso_real'])\n",
    "mean_error_on_train = np.mean(relative_error_on_train)\n",
    "max_error_on_train = np.max(relative_error_on_train)\n",
    "rmse = np.sqrt(mean_squared_error(y_train_full['conso_real'], predictions_train))\n",
    "\n",
    "print(\"Erreur moyenne sur le jeu de train : \" + str(mean_error_on_train * 100) + \" %\")\n",
    "print(\"Erreur max sur le jeu de train : \" + str(max_error_on_train * 100) + \" %\")\n",
    "print(\"RMSE : \" + str(rmse) + \" MW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "relative_error_on_val = np.abs((y_validation_full['conso_real'] - predictions_val) / y_validation_full['conso_real'])\n",
    "mean_error_on_val = np.mean(relative_error_on_val)\n",
    "max_error_on_val = np.max(relative_error_on_val)\n",
    "rmse = np.sqrt(mean_squared_error(y_validation_full['conso_real'], predictions_val))\n",
    "\n",
    "print(\"Erreur moyenne sur le jeu de validation : \" + str(mean_error_on_val * 100) + \" %\")\n",
    "print(\"Erreur max sur le jeu de validation : \" + str(max_error_on_val * 100) + \" %\")\n",
    "print(\"RMSE : \" + str(rmse) + \" MW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "relative_error_on_test = np.abs((y_test_full['conso_real'] - predictions_test) / y_test_full['conso_real'])\n",
    "mean_error_on_test = np.mean(relative_error_on_test)\n",
    "max_error_on_test = np.max(relative_error_on_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_full['conso_real'], predictions_test))\n",
    "\n",
    "print(\"Erreur moyenne sur le jeu de test : \" + str(mean_error_on_test * 100) + \" %\")\n",
    "print(\"Erreur max sur le jeu de test : \" + str(max_error_on_test * 100) + \" %\")\n",
    "print(\"RMSE : \" + str(rmse) + \" MW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "iplot([{\"x\": y_test_full['ds'], \"y\": y_test_full['conso_real'], \"name\": \"realise\"},\n",
    "       {\"x\": y_test_full['ds'], \"y\": predictions_test, \"name\": \"prevision\"}\n",
    "      ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'erreur est ici comparable à celle des autres modèles en machine Learning (random forest, xgboost). Cela peut nous conforter dans le fait que notre réseau de neurones s'est créé de bonnes représentations pour ces variables calendaires. \n",
    "\n",
    "La différence en performance peut devenir plus flagrante lorsque l'on intègre des variables à une maille très granulaire (les pixels d'une images, la température dans toutes les villes de France) avec une forte interdépendance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour inspecter dynamiquement des visualisations, la librairie plotly se révèle très utile.\n",
    "Ci-dessous vous pouvez identifier les jours et heures qui présentent les erreurs les plus importantes pour ensuite imaginer ce qui a pu pêcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "iplot([{\"x\": y_test_full['ds'], \"y\": relative_error_on_test}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "\n",
    "* Quelles sont les heures ou les journées avec les erreurs les plus importantes. Avez-vous une idée à quoi pourrait correspondre ces heures ou ces jours ?\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V) A vous de jouer, faites fonctionner vos neurones naturels\n",
    "\n",
    "<img src=\"pictures/we-need-you.png\" width=500 >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Challenge**: entrainez et testez votre nouveau modèle avec de nouvelles variables et paramètres choisies\n",
    "\n",
    "N'hésitez pas à largement copier-coller des morceaux de code ci-dessus ;-)  \n",
    "Venez partager vos investigations sur cette google sheet : https://docs.google.com/spreadsheets/d/1oIx8jjzIh7Ugp3ZJMCOEwns6KCJxo4ua_jW5hIvjjFI/edit?usp=sharing\n",
    "\n",
    "Quelques idées si vous n'êtes pas inspirés :\n",
    "- essayer d'autres hyperparamètres (learning rate, taille des minibatch, nombre de couches...)\n",
    "- regarder ce qu'il se passe si on utilise des variables non normalisées\n",
    "- ajouter d'autres variables en entrée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Votre modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rappel des variables explicatives à disposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Initialement\n",
    "x_train_full.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choix des variables explicatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sélectionne les variables que l'on souhaite conserver en précisant simplement à quelle catégorie elles appartiennent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Sélectionnons un sous-ensemble de ces variables\n",
    "\n",
    "######### TO DO #########\n",
    "\n",
    "# Prenez ce que vous voulez dans \"x_light_columns\"\n",
    "x_light_columns = [elt for elt in x.columns if elt not in \n",
    "                   [\"ds\", \"temperature_real_24h_avant\", \"temperature_prevue\", \"conso_real_24h_avant\"]\n",
    "                  ]\n",
    "#########################\n",
    "\n",
    "x_train_light = x_train_full[x_light_columns]\n",
    "x_validation_light = x_validation_full[x_light_columns]\n",
    "x_test_light = x_test_full[x_light_columns]\n",
    "\n",
    "print(x_train_light.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du réseau de neurones, hyper-paramétrage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez jouer sur l'architecture de votre reseau de neurones ici en précisant le nombre de couches et la taille des couches dans le vecteur hiddenLayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "n_inputs = x_train_light.shape[1]  # nombre d'entrées du modèle\n",
    "n_outputs = y_train_light.shape[1]\n",
    "\n",
    "######### TO DO #########\n",
    "# votre choix  (nombre de couche et taille des couches)\n",
    "hidden_layers = [n_inputs, n_inputs, n_inputs, n_inputs, n_inputs]\n",
    "\n",
    "# learning rate\n",
    "lr = 0.01\n",
    "\n",
    "# nombre d'epoch (= nombre de fois ou chaque element du jeu de données sera utilisé pour \"apprendre\")\n",
    "nb_epochs = 100\n",
    "\n",
    "# batch size (= nombre de lignes de la base de données qui seront utilisées pour calculer \n",
    "# les gradients lors d'une iteration d'apprentissage)\n",
    "batch_size = 64\n",
    "#########################\n",
    "\n",
    "# NB: le nombre total \"d'iteration de descente de gradient\" est donc\n",
    "# (taille base apprentissage / batch_size) * nb_epochs\n",
    "\n",
    "mon_reseau_de_neurones = new_keras_model(n_inputs, n_outputs, hidden_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# on affiche le nombre de paramètres de votre modèle avec la fonction \"summary\" de Keras\n",
    "mon_reseau_de_neurones.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "mon_reseau_de_neurones.compile(\n",
    "    loss='mean_squared_error', \n",
    "    optimizer=Adam(lr=lr),  # <=  TODO : vous pouvez jouer avec ça aussi\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard\n",
    "Notre utilitaire de tensorflow qui permet de visualiser en temps réel les courbes d'apprentissage des réseau de neurones et est donc utile pour arrêter l'apprentissage si les progrès sont faibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Donner un nom a votre modele pour le retrouver dans les logs tensorboard\n",
    "model_name = \"my_own_model_\" + datetime.datetime.now().strftime(\"%H-%M-%S\")\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(model_name),histogram_freq=1)\n",
    "\n",
    "\n",
    "#lancement dans le notebook\n",
    "#vous pouvez rafraîchir tensorboard lorsque un modèle est entraîné pour voir la progression tensorboard \n",
    "%tensorboard --logdir logs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement\n",
    "\n",
    "La cellule suivante peut prendre un peu de temps à s'exécuter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "mon_reseau_de_neurones.fit(\n",
    "    x_train_light, \n",
    "    y_train_light, \n",
    "    epochs=nb_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_validation_light, y_validation_light),\n",
    "    callbacks=[tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation de la qualité du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "predictions_train_scaled = mon_reseau_de_neurones.predict(x_train_light)\n",
    "predictions_train = scaler_conso_nat.inverse_transform(predictions_train_scaled).reshape(-1)\n",
    "\n",
    "predictions_val_scaled = mon_reseau_de_neurones.predict(x_validation_light)\n",
    "predictions_val = scaler_conso_nat.inverse_transform(predictions_val_scaled).reshape(-1)\n",
    "\n",
    "predictions_test_scaled = mon_reseau_de_neurones.predict(x_test_light)\n",
    "predictions_test = scaler_conso_nat.inverse_transform(predictions_test_scaled).reshape(-1)\n",
    "\n",
    "print(predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "iplot([{\"x\": y_test_full['ds'], \"y\": y_test_full['conso_real'], \"name\": \"realise\"},\n",
    "       {\"x\": y_test_full['ds'], \"y\": predictions_test, \"name\": \"prevision\"}\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "relative_error_on_train = np.abs((y_train_full['conso_real'] - predictions_train) / y_train_full['conso_real'])\n",
    "mean_error_on_train = np.mean(relative_error_on_train)\n",
    "max_error_on_train = np.max(relative_error_on_train)\n",
    "rmse = np.sqrt(mean_squared_error(y_train_full['conso_real'], predictions_train))\n",
    "\n",
    "print(\"Erreur moyenne sur le jeu de train : \" + str(mean_error_on_train * 100) + \" %\")\n",
    "print(\"Erreur max sur le jeu de train : \" + str(max_error_on_train * 100) + \" %\")\n",
    "print(\"RMSE : \" + str(rmse) + \" MW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "relative_error_on_val = np.abs((y_validation_full['conso_real'] - predictions_val) / y_validation_full['conso_real'])\n",
    "mean_error_on_val = np.mean(relative_error_on_val)\n",
    "max_error_on_val = np.max(relative_error_on_val)\n",
    "rmse = np.sqrt(mean_squared_error(y_validation_full['conso_real'], predictions_val))\n",
    "\n",
    "print(\"Erreur moyenne sur le jeu de validation : \" + str(mean_error_on_val * 100) + \" %\")\n",
    "print(\"Erreur max sur le jeu de validation : \" + str(max_error_on_val * 100) + \" %\")\n",
    "print(\"RMSE : \" + str(rmse) + \" MW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "relative_error_on_test = np.abs((y_test_full['conso_real'] - predictions_test) / y_test_full['conso_real'])\n",
    "\n",
    "mean_error_on_test = np.mean(relative_error_on_test)\n",
    "max_error_on_test = np.max(relative_error_on_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_full['conso_real'], predictions_test))\n",
    "\n",
    "print(\"Erreur moyenne sur le jeu de test : \" + str(mean_error_on_test * 100) + \" %\")\n",
    "print(\"Erreur max sur le jeu de test : \" + str(max_error_on_test * 100) + \" %\")\n",
    "print(\"RMSE : \" + str(rmse) + \" MW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "iplot([{\"x\": y_test_full['ds'], \"y\": 100. * relative_error_on_test, \"name\": \"erreur relative (%)\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour aller encore plus loin\n",
    "\n",
    "Le modèle ci-dessus peut être rendu encore plus performant par exemple en considérant des features comme \"jour d'avant vacances\", \"jour d'après vacances\"... \n",
    "\n",
    "Passer du temps à tuner les hyper-paramètres serait certainement bénéfique aussi.\n",
    "\n",
    "De manière assez surprenante, élargir le réseau de neurones pour prédire les consommations régionales peut également améliorer la qualité de la prédiction de l'échelle nationale. C'est l'idée du multi-tasking. Pour intégrer ces données supplémentaire, il est nécessaire de passer un peu de temps pour repréparer les données : aussi rendez-vous dans le TP *preparation_donnees.ipynb*.\n",
    "\n",
    "On pourra également considérer en sortie du modèle non pas la prédiction pour juste 24 heures plus tard, mais plutôt pour une plage horaire [1 heure plus tard, ..., 24 heures plus tard]. Ceci permet de capter des dynamiques. Un réseau de neurones de type convolutionnel serait aussi une option crédible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec Python 3.11.8 ('colab20240404') nécessitent ipykernel package.\n",
      "\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\n",
      "\u001b[1;31mCommande : 'conda install -n colab20240404 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3.11.8 ('colab20240404')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b49155285f7dceac7a84150eb00a1a33888751f0fb081075068988e96620e8fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
